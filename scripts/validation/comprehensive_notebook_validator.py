#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„Notebookæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å…¨notebookã®å‹•ä½œã‚’æ¤œè¨¼ã—ã€ç ”ç©¶æ•´åˆæ€§ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç·åˆçš„ã«ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import os
import sys
import time
import json
import subprocess
import warnings
from pathlib import Path
from typing import Dict, List, Any, Optional
import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¨­å®š
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
os.chdir(project_root)

try:
    import nbformat
    from nbclient import NotebookClient
    from nbclient.exceptions import CellExecutionError
    NBCLIENT_AVAILABLE = True
except ImportError:
    print("âš ï¸ nbclientãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬çš„ãªæ¤œè¨¼ã®ã¿å®Ÿè¡Œã—ã¾ã™ã€‚")
    NBCLIENT_AVAILABLE = False

from src.dsge_model import DSGEModel, ModelParameters
from src.tax_simulator import EnhancedTaxSimulator, TaxReform
from src.research_warnings import ResearchWarning


class NotebookValidator:
    """åŒ…æ‹¬çš„Notebookæ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.results = {}
        self.notebooks_dir = project_root / "notebooks"
        self.test_report = {
            'summary': {},
            'detailed_results': {},
            'research_integrity': {},
            'performance_metrics': {},
            'error_scenarios': {}
        }
    
    def validate_all_notebooks(self) -> Dict[str, Any]:
        """å…¨notebookã®åŒ…æ‹¬çš„æ¤œè¨¼"""
        print("=" * 60)
        print("åŒ…æ‹¬çš„Notebookæ¤œè¨¼é–‹å§‹")
        print("=" * 60)
        
        notebook_files = list(self.notebooks_dir.glob("*.ipynb"))
        
        for nb_file in notebook_files:
            print(f"\n{'='*50}")
            print(f"æ¤œè¨¼ä¸­: {nb_file.name}")
            print(f"{'='*50}")
            
            result = self.validate_single_notebook(nb_file)
            self.results[str(nb_file)] = result
        
        # æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        self.generate_comprehensive_report()
        
        return self.results
    
    def validate_single_notebook(self, notebook_path: Path) -> Dict[str, Any]:
        """å˜ä¸€notebookã®æ¤œè¨¼"""
        result = {
            'basic_execution': self._test_basic_execution(notebook_path),
            'research_integrity': self._test_research_integrity(notebook_path),
            'error_handling': self._test_error_handling(notebook_path),
            'performance': self._test_performance(notebook_path),
            'api_compatibility': self._test_api_compatibility(notebook_path)
        }
        
        return result
    
    def _test_basic_execution(self, notebook_path: Path) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªå®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        print("\n--- åŸºæœ¬å®Ÿè¡Œãƒ†ã‚¹ãƒˆ ---")
        
        if not NBCLIENT_AVAILABLE:
            return {'status': 'skipped', 'reason': 'nbclient unavailable'}
        
        try:
            with open(notebook_path, 'r', encoding='utf-8') as f:
                nb = nbformat.read(f, as_version=4)
            
            # åŸºæœ¬çš„ãªåˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥
            self._inject_test_setup(nb)
            
            client = NotebookClient(
                nb,
                timeout=300,
                kernel_name='python3',
                allow_errors=True
            )
            
            start_time = time.time()
            
            try:
                client.execute()
                execution_time = time.time() - start_time
                
                # ã‚»ãƒ«å®Ÿè¡Œçµæœã®åˆ†æ
                executed_cells = 0
                error_cells = 0
                
                for cell in nb.cells:
                    if cell.cell_type == 'code' and cell.get('outputs'):
                        executed_cells += 1
                        
                        for output in cell.outputs:
                            if output.get('output_type') == 'error':
                                error_cells += 1
                                break
                
                success_rate = (executed_cells - error_cells) / max(executed_cells, 1)
                
                print(f"âœ… å®Ÿè¡Œå®Œäº†: {executed_cells}ã‚»ãƒ«å®Ÿè¡Œã€{error_cells}ã‚¨ãƒ©ãƒ¼")
                print(f"æˆåŠŸç‡: {success_rate:.1%}ã€å®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’")
                
                return {
                    'status': 'success',
                    'executed_cells': executed_cells,
                    'error_cells': error_cells,
                    'success_rate': success_rate,
                    'execution_time': execution_time
                }
                
            except Exception as e:
                print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                return {
                    'status': 'execution_failed',
                    'error': str(e),
                    'execution_time': time.time() - start_time
                }
                
        except Exception as e:
            print(f"âŒ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {'status': 'load_failed', 'error': str(e)}
    
    def _test_research_integrity(self, notebook_path: Path) -> Dict[str, Any]:
        """ç ”ç©¶æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        print("\n--- ç ”ç©¶æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ ---")
        
        integrity_issues = []
        warnings_detected = []
        
        try:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
            params = ModelParameters.from_json('config/parameters.json')
            model = DSGEModel(params)
            
            # DummySteadyStateæ¤œå‡ºãƒ†ã‚¹ãƒˆ
            with warnings.catch_warnings(record=True) as w:
                warnings.simplefilter("always")
                
                # ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ã§ã®ãƒ†ã‚¹ãƒˆ
                simple_simulator = EnhancedTaxSimulator(model, use_simple_model=True)
                reform = TaxReform("æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ", tau_c=0.12)
                result = simple_simulator.simulate_reform(reform, periods=5)
                
                # è­¦å‘Šã®åˆ†æ
                for warning in w:
                    warning_msg = str(warning.message)
                    if any(keyword in warning_msg.lower() for keyword in 
                          ['dummy', 'hardcoded', 'research', 'fallback']):
                        warnings_detected.append(warning_msg)
                        
                        if 'dummy' in warning_msg.lower():
                            integrity_issues.append("DummySteadyStateä½¿ç”¨æ¤œå‡º")
            
            # DummySteadyStateã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ¤œå‡ºï¼ˆã‚¯ãƒ©ã‚¹åã§åˆ¤å®šï¼‰
            if hasattr(result, 'steady_state_baseline'):
                baseline_type = type(result.steady_state_baseline).__name__
                if 'Dummy' in baseline_type:
                    integrity_issues.append(f"DummySteadyStateã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½¿ç”¨: {baseline_type}")
            
            if hasattr(result, 'steady_state_reform'):
                reform_type = type(result.steady_state_reform).__name__
                if 'Dummy' in reform_type:
                    integrity_issues.append(f"DummySteadyStateã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½¿ç”¨: {reform_type}")
            
            # ç¦åˆ©åšç”Ÿè¨ˆç®—ã®æ¤œè¨¼
            if hasattr(result, 'welfare_change'):
                if result.welfare_change == 0.0:
                    integrity_issues.append("ç¦åˆ©å¤‰åŒ–ã‚¼ãƒ­ï¼ˆè¨ˆç®—å¤±æ•—ã®å¯èƒ½æ€§ï¼‰")
                elif np.isnan(result.welfare_change) or np.isinf(result.welfare_change):
                    integrity_issues.append("ç¦åˆ©å¤‰åŒ–ãŒç„¡é™å€¤/NaN")
            
            print(f"è­¦å‘Šæ¤œå‡º: {len(warnings_detected)}å€‹")
            print(f"æ•´åˆæ€§å•é¡Œ: {len(integrity_issues)}å€‹")
            
            if integrity_issues:
                for issue in integrity_issues:
                    print(f"  âš ï¸ {issue}")
            
            status = 'clean' if not integrity_issues else 'issues_found'
            
            return {
                'status': status,
                'integrity_issues': integrity_issues,
                'warnings_detected': warnings_detected,
                'dummy_state_used': 'DummySteadyState' in str(integrity_issues)
            }
            
        except Exception as e:
            print(f"âŒ ç ”ç©¶æ•´åˆæ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'status': 'test_failed',
                'error': str(e)
            }
    
    def _test_error_handling(self, notebook_path: Path) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        print("\n--- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ ---")
        
        error_scenarios = [
            {'name': 'æ¥µç«¯ãªç¨ç‡', 'params': {'tau_c': 0.99, 'tau_l': 0.99}},
            {'name': 'ã‚¼ãƒ­ç¨ç‡', 'params': {'tau_c': 0.0, 'tau_l': 0.0}},
            {'name': 'è² ã®ç¨ç‡', 'params': {'tau_c': -0.1, 'tau_l': -0.1}},
        ]
        
        handled_errors = 0
        total_scenarios = len(error_scenarios)
        
        for scenario in error_scenarios:
            try:
                # åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ä½œæˆ
                params = ModelParameters.from_json('config/parameters.json')
                model = DSGEModel(params)
                simulator = EnhancedTaxSimulator(model)
                
                # ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ
                reform = TaxReform(
                    scenario['name'],
                    **scenario['params']
                )
                
                try:
                    result = simulator.simulate_reform(reform, periods=5)
                    
                    # çµæœã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                    if (hasattr(result, 'welfare_change') and 
                        (np.isnan(result.welfare_change) or np.isinf(result.welfare_change))):
                        handled_errors += 1
                        print(f"âœ… {scenario['name']}: ç•°å¸¸çµæœæ¤œå‡º")
                    else:
                        print(f"âš ï¸ {scenario['name']}: äºˆæœŸã—ãªã„æ­£å¸¸çµ‚äº†")
                        
                except Exception as expected_error:
                    handled_errors += 1
                    print(f"âœ… {scenario['name']}: é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ - {type(expected_error).__name__}")
                    
            except Exception as e:
                print(f"âŒ {scenario['name']}: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ - {type(e).__name__}")
        
        error_handling_rate = handled_errors / total_scenarios
        
        print(f"ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆåŠŸç‡: {error_handling_rate:.1%}")
        
        return {
            'status': 'good' if error_handling_rate >= 0.7 else 'needs_improvement',
            'handling_rate': error_handling_rate,
            'scenarios_tested': total_scenarios,
            'scenarios_handled': handled_errors
        }
    
    def _test_performance(self, notebook_path: Path) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        print("\n--- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ---")
        
        try:
            params = ModelParameters.from_json('config/parameters.json')
            model = DSGEModel(params)
            
            # ç•°ãªã‚‹ãƒ¢ãƒ¼ãƒ‰ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
            performance_data = {}
            
            test_scenarios = [
                {'name': 'ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰', 'config': {'use_simple_model': True}},
                {'name': 'å®Œå…¨ãƒ¢ãƒ¼ãƒ‰', 'config': {'use_simple_model': False}},
                {'name': 'ç°¡æ˜“ç·šå½¢åŒ–', 'config': {'use_simple_linearization': True}}
            ]
            
            for scenario in test_scenarios:
                try:
                    start_time = time.time()
                    
                    simulator = EnhancedTaxSimulator(model, **scenario['config'])
                    reform = TaxReform("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", tau_c=0.12)
                    result = simulator.simulate_reform(reform, periods=20)
                    
                    execution_time = time.time() - start_time
                    
                    performance_data[scenario['name']] = {
                        'execution_time': execution_time,
                        'success': True
                    }
                    
                    print(f"âœ… {scenario['name']}: {execution_time:.2f}ç§’")
                    
                except Exception as e:
                    performance_data[scenario['name']] = {
                        'execution_time': None,
                        'success': False,
                        'error': str(e)
                    }
                    print(f"âŒ {scenario['name']}: ã‚¨ãƒ©ãƒ¼ - {type(e).__name__}")
            
            return {
                'status': 'completed',
                'performance_data': performance_data
            }
            
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'status': 'test_failed',
                'error': str(e)
            }
    
    def _test_api_compatibility(self, notebook_path: Path) -> Dict[str, Any]:
        """APIäº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        print("\n--- APIäº’æ›æ€§ãƒ†ã‚¹ãƒˆ ---")
        
        try:
            params = ModelParameters.from_json('config/parameters.json')
            model = DSGEModel(params)
            
            # ç•°ãªã‚‹è¨­å®šã§ã®APIä¸€è²«æ€§ç¢ºèª
            api_tests = [
                {'name': 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š', 'args': [], 'kwargs': {}},
                {'name': 'ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰', 'args': [], 'kwargs': {'use_simple_model': True}},
                {'name': 'ç°¡æ˜“ç·šå½¢åŒ–', 'args': [], 'kwargs': {'use_simple_linearization': True}}
            ]
            
            api_compatibility = {}
            required_attributes = ['name', 'welfare_change', 'baseline_path', 'reform_path']
            
            for test_config in api_tests:
                try:
                    simulator = EnhancedTaxSimulator(model, *test_config['args'], **test_config['kwargs'])
                    reform = TaxReform("APIäº’æ›æ€§ãƒ†ã‚¹ãƒˆ", tau_c=0.11)
                    result = simulator.simulate_reform(reform, periods=10)
                    
                    # APIä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
                    missing_attrs = []
                    for attr in required_attributes:
                        if not hasattr(result, attr):
                            missing_attrs.append(attr)
                    
                    api_compatibility[test_config['name']] = {
                        'success': len(missing_attrs) == 0,
                        'missing_attributes': missing_attrs
                    }
                    
                    if missing_attrs:
                        print(f"âš ï¸ {test_config['name']}: ä¸è¶³å±æ€§ {missing_attrs}")
                    else:
                        print(f"âœ… {test_config['name']}: APIäº’æ›æ€§ç¢ºèª")
                        
                except Exception as e:
                    api_compatibility[test_config['name']] = {
                        'success': False,
                        'error': str(e)
                    }
                    print(f"âŒ {test_config['name']}: ã‚¨ãƒ©ãƒ¼ - {type(e).__name__}")
            
            compatible_apis = sum(1 for test in api_compatibility.values() if test.get('success', False))
            compatibility_rate = compatible_apis / len(api_tests)
            
            return {
                'status': 'good' if compatibility_rate >= 0.8 else 'needs_improvement',
                'compatibility_rate': compatibility_rate,
                'detailed_results': api_compatibility
            }
            
        except Exception as e:
            print(f"âŒ APIäº’æ›æ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'status': 'test_failed',
                'error': str(e)
            }
    
    def _inject_test_setup(self, nb):
        """ãƒ†ã‚¹ãƒˆç”¨ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥"""
        setup_code = '''
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨è¨­å®š
import os
import sys
import warnings
warnings.filterwarnings('ignore', category=DeprecationWarning)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¨­å®š
project_root = os.path.abspath('.')
os.chdir(project_root)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
os.makedirs('results', exist_ok=True)
'''
        
        setup_cell = nbformat.v4.new_code_cell(source=setup_code)
        nb.cells.insert(0, setup_cell)
    
    def generate_comprehensive_report(self):
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        print("\n" + "=" * 60)
        print("åŒ…æ‹¬çš„æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        print("=" * 60)
        
        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆã®è¨ˆç®—
        total_notebooks = len(self.results)
        successful_executions = sum(1 for r in self.results.values() 
                                  if r.get('basic_execution', {}).get('status') == 'success')
        
        research_clean = sum(1 for r in self.results.values()
                           if r.get('research_integrity', {}).get('status') == 'clean')
        
        good_error_handling = sum(1 for r in self.results.values()
                                if r.get('error_handling', {}).get('status') == 'good')
        
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'total_notebooks': total_notebooks,
                'successful_executions': successful_executions,
                'execution_success_rate': successful_executions / max(total_notebooks, 1),
                'research_integrity_clean': research_clean,
                'good_error_handling': good_error_handling
            },
            'detailed_results': self.results,
            'recommendations': self._generate_recommendations()
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_file = project_root / 'results' / 'comprehensive_notebook_validation_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        # äººé–“å¯èª­ãƒ¬ãƒãƒ¼ãƒˆ
        text_report_file = project_root / 'results' / 'notebook_validation_summary.txt'
        with open(text_report_file, 'w', encoding='utf-8') as f:
            self._write_text_report(f, report)
        
        print(f"\nğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å…ˆ:")
        print(f"  è©³ç´°: {report_file}")
        print(f"  ã‚µãƒãƒªãƒ¼: {text_report_file}")
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        self._print_summary(report)
    
    def _generate_recommendations(self) -> List[str]:
        """æ”¹å–„ææ¡ˆã®ç”Ÿæˆ"""
        recommendations = []
        
        # ç ”ç©¶æ•´åˆæ€§ã®å•é¡Œ
        dummy_usage_detected = any(
            r.get('research_integrity', {}).get('dummy_state_used', False)
            for r in self.results.values()
        )
        
        if dummy_usage_detected:
            recommendations.append(
                "ğŸš¨ CRITICAL: DummySteadyStateä½¿ç”¨æ¤œå‡º - å­¦è¡“ç ”ç©¶ã«ã¯ä½¿ç”¨ä¸å¯ã€‚"
                "use_simple_model=Falseã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            )
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        poor_error_handling = any(
            r.get('error_handling', {}).get('status') == 'needs_improvement'
            for r in self.results.values()
        )
        
        if poor_error_handling:
            recommendations.append(
                "âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„ãŒå¿…è¦ã€‚æ¥µç«¯ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®"
                "robustæ€§ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚"
            )
        
        return recommendations
    
    def _write_text_report(self, f, report):
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã®æ›¸ãå‡ºã—"""
        f.write("NotebookåŒ…æ‹¬çš„æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"æ¤œè¨¼æ—¥æ™‚: {report['timestamp']}\n")
        f.write(f"å¯¾è±¡Notebookæ•°: {report['summary']['total_notebooks']}\n\n")
        
        f.write("å®Ÿè¡ŒæˆåŠŸç‡: {:.1%}\n".format(report['summary']['execution_success_rate']))
        f.write(f"ç ”ç©¶æ•´åˆæ€§ã‚¯ãƒªãƒ¼ãƒ³: {report['summary']['research_integrity_clean']}ä»¶\n")
        f.write(f"ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è‰¯å¥½: {report['summary']['good_error_handling']}ä»¶\n\n")
        
        f.write("æ”¹å–„ææ¡ˆ:\n")
        for rec in report['recommendations']:
            f.write(f"  - {rec}\n")
        
        f.write("\nè©³ç´°çµæœ:\n")
        for notebook, result in report['detailed_results'].items():
            f.write(f"\n{Path(notebook).name}:\n")
            f.write(f"  åŸºæœ¬å®Ÿè¡Œ: {result.get('basic_execution', {}).get('status', 'unknown')}\n")
            f.write(f"  ç ”ç©¶æ•´åˆæ€§: {result.get('research_integrity', {}).get('status', 'unknown')}\n")
            f.write(f"  ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: {result.get('error_handling', {}).get('status', 'unknown')}\n")
    
    def _print_summary(self, report):
        """ã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º"""
        print("\n" + "=" * 50)
        print("ğŸ“‹ æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 50)
        
        summary = report['summary']
        print(f"å¯¾è±¡Notebookæ•°: {summary['total_notebooks']}")
        print(f"å®Ÿè¡ŒæˆåŠŸç‡: {summary['execution_success_rate']:.1%}")
        print(f"ç ”ç©¶æ•´åˆæ€§ã‚¯ãƒªãƒ¼ãƒ³: {summary['research_integrity_clean']}/{summary['total_notebooks']}")
        print(f"ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è‰¯å¥½: {summary['good_error_handling']}/{summary['total_notebooks']}")
        
        if report['recommendations']:
            print("\nğŸ”§ ä¸»ãªæ”¹å–„ææ¡ˆ:")
            for rec in report['recommendations'][:3]:  # ä¸Šä½3ã¤
                print(f"  â€¢ {rec}")
        
        print("\nâœ… æ¤œè¨¼å®Œäº†")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    validator = NotebookValidator()
    results = validator.validate_all_notebooks()
    
    return 0 if results else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)